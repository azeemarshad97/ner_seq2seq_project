{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\azeem\\Documents\\UNIGE\\MSc CS\\Semester IV\\METL\\ner_seq2seq_project\\notebooks\n",
      "Parent directory: d:\\azeem\\Documents\\UNIGE\\MSc CS\\Semester IV\\METL\\ner_seq2seq_project\n",
      "Current working directory: d:\\azeem\\Documents\\UNIGE\\MSc CS\\Semester IV\\METL\\ner_seq2seq_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f'Current working directory: {os.getcwd()}')\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "print(f'Parent directory: {parent_dir}')\n",
    "os.chdir(parent_dir)\n",
    "print(f'Current working directory: {os.getcwd()}')\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# from src.neural_baseline import *\n",
    "from neural_baseline import *\n",
    "from src.utils.conlleval import *\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "%autoreload 2 \n",
    "\n",
    "# make figures appear inline\n",
    "# %matplotlib inline "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(dataset, ner_model, mapping):\n",
    "    all_true_tag_ids, all_predicted_tag_ids = [], []\n",
    "    \n",
    "    for x, y in dataset:\n",
    "        output = ner_model.predict(x, verbose=0)  # set verbose to 0\n",
    "        predictions = np.argmax(output, axis=-1)\n",
    "        predictions = np.reshape(predictions, [-1])\n",
    "\n",
    "        true_tag_ids = np.reshape(y, [-1])\n",
    "\n",
    "        mask = (true_tag_ids > 0) & (predictions > 0)\n",
    "        true_tag_ids = true_tag_ids[mask]\n",
    "        predicted_tag_ids = predictions[mask]\n",
    "\n",
    "        all_true_tag_ids.append(true_tag_ids)\n",
    "        all_predicted_tag_ids.append(predicted_tag_ids)\n",
    "\n",
    "    all_true_tag_ids = np.concatenate(all_true_tag_ids)\n",
    "    all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n",
    "\n",
    "    predicted_tags = [mapping[tag] for tag in all_predicted_tag_ids]\n",
    "    real_tags = [mapping[tag] for tag in all_true_tag_ids]\n",
    "    \n",
    "    res = evaluate(real_tags, predicted_tags, verbose = True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline n°1: Neural Network Implementation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data and preparing vocabulary of size 20000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (C:/Users/azeem/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f92e4edada54dd9befe52d2c385eb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing datasets...\n",
      "creating model...\n",
      "\n",
      "training model...\n",
      "\n",
      "Epoch 1/10\n",
      "439/439 [==============================] - 11s 19ms/step - loss: 0.6282\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 7s 17ms/step - loss: 0.2512\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 9s 20ms/step - loss: 0.1540\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 7s 17ms/step - loss: 0.1191\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 7s 16ms/step - loss: 0.0957\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 7s 16ms/step - loss: 0.0786\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 7s 15ms/step - loss: 0.0654\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 7s 16ms/step - loss: 0.0573\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 8s 17ms/step - loss: 0.0514\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 7s 16ms/step - loss: 0.0465\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "sample_text = \"eu rejects german call to boycott british lamb\"\n",
    "\n",
    "\n",
    "print(f\"processing data and preparing vocabulary of size {vocab_size}...\")    \n",
    "conll_data = load_and_prepare_data()\n",
    "\n",
    "mapping = make_tag_lookup_table()\n",
    "\n",
    "# vocab_size = 20000\n",
    "vocabulary = get_vocabulary(conll_data, vocab_size)\n",
    "\n",
    "print(f\"preparing datasets...\")\n",
    "lookup_layer = keras.layers.StringLookup(vocabulary=vocabulary)\n",
    "\n",
    "# batch_size = 32\n",
    "train_dataset, val_dataset = prepare_datasets(vocabulary, batch_size)\n",
    "\n",
    "num_tags = len(mapping)\n",
    "\n",
    "print(f\"creating model...\\n\")\n",
    "ner_model = create_model(num_tags, vocab_size)\n",
    "\n",
    "print(f\"training model...\\n\")\n",
    "compile_and_fit(ner_model, train_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 220ms/step\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O']\n",
      "\n",
      "calculating metrics...\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5219 phrases; correct: 3848.\n",
      "accuracy:  62.55%; (non-O)\n",
      "accuracy:  93.40%; precision:  73.73%; recall:  64.76%; FB1:  68.95\n",
      "              LOC: precision:  83.97%; recall:  79.26%; FB1:  81.55  1734\n",
      "             MISC: precision:  75.32%; recall:  64.53%; FB1:  69.51  790\n",
      "              ORG: precision:  67.64%; recall:  58.61%; FB1:  62.80  1162\n",
      "              PER: precision:  65.95%; recall:  54.89%; FB1:  59.91  1533\n",
      "\n",
      "\n",
      "precision: \t73.73\n",
      "   recall: \t64.76\n",
      "       f1: \t68.95\n"
     ]
    }
   ],
   "source": [
    "print(predict_sample(ner_model, sample_text, mapping, lookup_layer))\n",
    "\n",
    "print(f\"\\ncalculating metrics...\\n\")\n",
    "res = calculate_metrics(val_dataset, ner_model, mapping)\n",
    "\n",
    "# res is a tuple of (precision, recall, f1), print it out beautifully\n",
    "print(\"\\n\")\n",
    "print(f\"precision: \\t{res[0]:.2f}\")\n",
    "print(f\"   recall: \\t{res[1]:.2f}\")\n",
    "print(f\"       f1: \\t{res[2]:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline n°2: CRF Implementation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from src.crf_baseline import * \n",
    "from IPython.display import display\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'NNP', 'B-NP', 'B-ORG'],\n",
       " ['rejects', 'VBZ', 'B-VP', 'O'],\n",
       " ['German', 'JJ', 'B-NP', 'B-MISC'],\n",
       " ['call', 'NN', 'I-NP', 'O'],\n",
       " ['to', 'TO', 'B-VP', 'O'],\n",
       " ['boycott', 'VB', 'I-VP', 'O'],\n",
       " ['British', 'JJ', 'B-NP', 'B-MISC'],\n",
       " ['lamb', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_raw_input(filename):\n",
    "    \"\"\"Read a train/test file and return the contents as a list of list of lists. \n",
    "    \n",
    "    The innermost list is a record of 4 items, one per word.\n",
    "    The middle-level list contains all the records in one sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    all_items = []\n",
    "\n",
    "    with open(filename) as fh:\n",
    "        current_item = []\n",
    "        all_items.append(current_item)\n",
    "\n",
    "        for line in fh:\n",
    "            tags = line.strip().split()\n",
    "            if len(tags) == 0 or tags[0] == '-DOCSTART-':\n",
    "                continue\n",
    "            current_item.append(tags)\n",
    "            if tags[0] == '.' and tags[1] == '.':\n",
    "                current_item = []\n",
    "                all_items.append(current_item)\n",
    "                \n",
    "    return all_items\n",
    "\n",
    "train_sents = read_raw_input('./data/CoNLL-2003_train.txt')\n",
    "test_sents = read_raw_input('./data/CoNLL-2003_test.txt')\n",
    "\n",
    "display(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>parse</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_seq_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boycott</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lamb</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  pos parse     ner\n",
       "word_seq_num                            \n",
       "0                  EU  NNP  B-NP   B-ORG\n",
       "1             rejects  VBZ  B-VP       O\n",
       "2              German   JJ  B-NP  B-MISC\n",
       "3                call   NN  I-NP       O\n",
       "4                  to   TO  B-VP       O\n",
       "5             boycott   VB  I-VP       O\n",
       "6             British   JJ  B-NP  B-MISC\n",
       "7                lamb   NN  I-NP       O\n",
       "8                   .    .     O       O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = all_sentences(train_sents)\n",
    "test_sents  = all_sentences(test_sents)\n",
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7375/7375 [03:00<00:00, 40.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = get_feature_values(train_sents)\n",
    "X_test = get_feature_values(test_sents)\n",
    "y_train, y_test = get_labels(train_sents), get_labels(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 41.4 s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=200,\n",
    "    verbose=False,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flat f1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "f1_score = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "print(f\" flat f1 score: {f1_score:.2f}\")\n",
    "\n",
    "report = calculate_metrics_crf(y_test, y_pred, labels)\n",
    "print(f\"{report}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement Proposition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
